## 基于Transformer轻量级高效精确的Conversational Representation对话系统ConveRT解密(一)


一、概述

        本文围绕下面这篇论文来分析基于Transformer的对话系统ConveRT(Conversational Representations from Transformer的缩写)背后的机制，特别是，它是如何实现一个高效和准确的对话系统。

        对于现实世界AI对话系统来说，使用BERT之类的预训练语言模型的结果并不理想，因为存在计算模型笨重，训练速度慢，训练成本昂贵等缺点。论文提出的ConveRT这种对话系统模型，是一个能够满足以下要求的对话任务预训练框架：

-effective

-affordable，意指训练成本不高

-quick to train，训练速度快

————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121912782
