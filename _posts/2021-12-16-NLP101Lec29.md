
## 基于Transformer的Poly-Encoder架构体系解密(二）第29课 

北京时间今晚21点第29课-周四-12月16号：基于Transformer的Poly-Encoder架构体系解密

1，基于Transformer的Bi-encoder解析 2，基于Transformer的Cross-encoder解析 3，基于Transformer的Poly-encoder解析

coveRT的code https://github.com/duanzhihua/ConveRT-pytorch

conveRT论文代码pytorch复现


本文继续围绕下面这篇论文来解析基于Transformer采用Poly-Encoder的架构是如何来平衡模型的速度和质量表现，以及它与Bi-encoder，Cross-encoder架构的对比等。


————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/122016741
