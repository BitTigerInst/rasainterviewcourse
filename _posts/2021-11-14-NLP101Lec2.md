## 语言模型与Transformer XL剖析


一、语言模型概述

1.什么是语言模型

        语言模型是预测词汇序列的概率分布的模型，先看下下面的公式：

        假设有一句话，由y1, y2, ... yn 等词汇顺序构成，可以理解为y2是在y1存在的情况下存在，y3是在y1和y2存在的情况下存在，y4是在y1, y2, y3存在的情况下存在，依次类推，yn是在y1, y2, ..., yn-1存在的情况下存在，所以用上述公式来计算这句话的词汇序列的概率分布，这就是贝叶斯中表达的条件概率。最右侧"=" 给出的是最简洁的表达方式，即在y<t 的条件下计算概率。

        语言模型本质上就是一个基于上下文环境的分类器，一个好的语言模型不仅是能够让正常语句表达在模型训练时得到更高的概率，而且最重要的是应该能在给定的上下文环境（或者称作历史信息）里预测接下来会发生什么。可以看下这句话“the cat is small”, 如果用语言模型来预测不同词汇的组合，好的模型应该得出下面的结论，即正常语句表述的概率更大：

P(the cat is small) > P(small the is cat)

再来看个例子：


————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121447718
