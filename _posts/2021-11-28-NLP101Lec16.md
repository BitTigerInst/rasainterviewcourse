## DIET:基于Transformer的轻量级多任务NLU系统（二）


一、概述

        DIET(Dual Intent and Entity Transformer)是一种基于Transformer的轻量级的运用于对话系统的语言理解模型，主要由以下几个关键部分组成：

    Featurization

        输入语句被处理为token序列(sequence)，这些token可以是完整词汇或者是词汇的一部分，这取决于进行featurization的pipeline。DIET在每个语句的最后添加了一个用于分类的特殊token”___CLS___”。每个输入token使用”sparse features”或者”dense features”或者这两者的组合来进行featurization，这就体现了一种“可插拔”的架构设计理念。Sparse features采用了token级别的”one-hot”编码（通过词库来实现）和字符级别的n-grams(n <= 5，根据工程实践来确定)的”multi-hot”编码，字符级别的n-grams包含了大量冗余的信息，为了避免过度拟合，所以对这些sparse features使用了dropout(残差网络处理)。Dense features可以是任何预训练的词嵌入。

如果使用ConveRT这种语句级别的encoder, 那么要注意的是___CLS___的顺序，即需要设置为语句embedding的第一个token。Sparse features通过一个具有共享权重的跨所有序列的全连接神经网络来传递以达到匹配dense features维度的目的。

————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121721142
