## 基于Transformer的Recipes for building an open-domain chatbot论文解析(二)

        本文继续围绕下面这篇论文来解析基于开放领域的对话机器人的架构，运用的skill及生成策略等内容。

三、总体介绍

        在NLP对话系统领域，研究表明基于大规模语料库进行预训练是很重要的，除了运用大规模的参数和训练数据集之外，还有以下两个方面需要注意：

    Blending Skills

        在通过微调数据来强调所期望的对话技能方面可以做出大的改进，选择任务时考虑能够使模型聚焦于对话吸引力，个性展现，对话共鸣，知识性，通过使用Blended Sill Talk(BST)提供的训练数据和初始化对话上下文（如人物角色特征和主题）可以针对上述几个方面获得较大的改善。使用BST的小模型也能达到或者超过不使用BST的大模型的表现效果。BST强调了期望的对话特点，通过使用BST能够减少从大规模语料库学到的不是所期望的

————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/122073111
