## 基于Retrieval的具有Fine-grained架构的对话系统(三）


        本文继续分析基于Retrieval的具有Fine-grained架构的对话系统这篇论文的算法和试验部分。

 

3.1 使用短上下文和响应配对训练(Short context-response Pair Training)

        关于如何对论文提出的模型BERT-FP(FP即fine-grained post-training的缩写)进行post training，是通过使用一个对话session里的所有的对话来构建多个short context-response pair来学习话语级别(utterance level)的交互。具体做法是把每一个话语作为响应，把它之前的k个相邻的话语作为上下文，如下图所示，绿色背景方框代表了一个short context-response pair，即由一个short context和一个response构成。  这里是把对话session里的每一个话语作为响应，意味着进行了更高层次的抽象和更多元化的表达，简而言之，response可以是系统的utterance，也可以是用户的utterance，这样就可以帮助模型学习到对话内部更精细化的内容。


————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121878539
