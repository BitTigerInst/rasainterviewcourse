## 基于Retrieval的具有Fine-grained架构的对话系统(四） 第24课

G

        本文继续围绕基于Retrieval的具有Fine-grained架构的对话系统这篇论文来进一步分析关于BERT-FP(即BERT Fine-grained Post-training的缩写)模型在各种试验条件下的表现及背后的机制。

5. 进一步分析

5.1 基于不同长度的”short context”的训练表现

        通常情况下，对于一个对话session中的一个response来说，与这个response相近的utterances之间的连贯性会更强，而与这个response距离较远的utterances之间的连贯性会变弱，基于这样的假设，下面通过试验来进行验证。此外，对于一个数据集来说比较适合的context 的长度，对于另外一个数据集可能并不适用，所以需要根据数据集的具体情况来调整context的长度，譬如下面图中的short context，可以看出它是由三句话(即3个utterance)组成：

-It says that …

-How do I …

-Open a …


————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121892869
