## 基于Transformer轻量级高效精确的Conversational Representation对话系统ConveRT解密(四)


       本文继续围绕ConveRT这篇论文来介绍如下内容。

四、试验部分

    3. 关于response selection任务

        基于Reddit数据集分别对single-context ConveRT和multi-context ConveRT模型进行了response selection任务测试，对于multi-context ConveRT，在训练时采用immediate和previous上下文的平均化表示来代表multi-context。这两个模型都是直接使用Reddit测试数据集而没有经过任何fine-tuning。另外也基于以下两个知名的response selection问题集进行了评价：

-AMAZONQA，一个电商数据集，以问答的形式包含了Amazon的产品信息

-DSTC7-UBUNTU，基于Ubuntu v2语料库，包含了超过1M的来自高科技领域的对话

        训练时learning rate从0.1开始，使用cos函数逐渐衰减到0.0001，batch size为256，在embedding和self-attention layer之后设置dropout为0.2。对于DSTC7-UBUNTU，在对话历史上下文

————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121983044
