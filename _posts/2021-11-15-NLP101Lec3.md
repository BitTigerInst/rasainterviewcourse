## GPT语言模型及预测实现机制


一、GPT语言模型概述

        语言模型从本质上来说就是一个基于上下文的分类器，GPT是open AI Lab推出的技术，包含了GPT-1, GPT-2, GPT3, 本文围绕GPT-2来展开分析。GPT-2模型在训练时是一个并行的结构，而在根据上下文做线上推理时是一个串行的结构，如下图所示，当我们在输入部分给定了上下文（绿色部分的词汇），那么GPT-2每一步推理只会给出一个词汇，即在输出部分会依次看到"A", "robot",

"may", "not" 等词汇：

         其背后推理机制使用了神经网络，输入部分的上下文或者历史信息被编码为一个向量(vector), 然后这个向量依次和matrix（由词库中的每个词汇向量构成）中的每个向量做乘法，两个向量相乘代表他们之间的紧密程度或者距离远近，在乘法之后，通过softmax函数变成0到1之间的概率。在工程设计时，如果词库的词汇量很大，譬如达到了10万级别，那么在做线上预测时，这样的向量运算会造成很大的性能问题，即给出预测词汇的时间可能会达到分钟级别，所以需要考虑如何选择最优的算法，譬如对词汇库进行合理的分组设计等。

        从架构层

————————————————
版权声明：本文为CSDN博主「m0_49380401」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_49380401/article/details/121462007
